{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFEYU2d/YxMA6mg0lZ3jWN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minahilmemon/skills-introduction-to-github/blob/main/User_Input.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "\n",
        "# ─── Configuration ──────────────────────────────────────────────────────────────\n",
        "FALLBACK_SNIPPET_LEN = 300  # show 300 characters for each fallback chunk\n",
        "\n",
        "# ─── Helpers ────────────────────────────────────────────────────────────────────\n",
        "\n",
        "def extract_keywords(text):\n",
        "    tokens = re.findall(r'\\w+', text.lower())\n",
        "    return list(dict.fromkeys(tok for tok in tokens if tok not in ENGLISH_STOP_WORDS))\n",
        "\n",
        "def highlight_text(text, keywords):\n",
        "    for kw in keywords:\n",
        "        pattern = re.compile(rf'\\b{re.escape(kw)}\\b', flags=re.IGNORECASE)\n",
        "        text = pattern.sub(lambda m: f\"**{m.group(0)}**\", text)\n",
        "    return text\n",
        "\n",
        "def calibrate_nn_median(embeddings):\n",
        "    \"\"\"\n",
        "    Nearest-neighbor based threshold calibration:\n",
        "      - Compute all pairwise cosine similarities\n",
        "      - For each segment, take the 2nd-highest (nearest-neighbor) similarity\n",
        "      - Return the median of those neighbor similarities\n",
        "    \"\"\"\n",
        "    sims = cosine_similarity(embeddings)\n",
        "    # for each row, sort and grab the 2nd-largest value (largest is self=1.0)\n",
        "    nn_sims = np.sort(sims, axis=1)[:, -2]\n",
        "    return float(np.median(nn_sims))\n",
        "\n",
        "# ─── Interactive lookup ─────────────────────────────────────────────────────────\n",
        "\n",
        "def interactive_lookup(\n",
        "    model,\n",
        "    segments,\n",
        "    segment_embeddings,\n",
        "    similarity_threshold: float,\n",
        "    boost_weight: float = 0.05\n",
        "):\n",
        "    \"\"\"\n",
        "    Interactive Q&A with:\n",
        "      - SBERT embeddings\n",
        "      - auto-calibrated NN-median threshold\n",
        "      - keyword filtering & boosting\n",
        "      - automatic top-3 fallback chunks (300-char each)\n",
        "      - keyword highlighting\n",
        "      - metadata display (title)\n",
        "    \"\"\"\n",
        "    assert len(segments) == segment_embeddings.shape[0], \\\n",
        "        \"segments length must match embeddings rows\"\n",
        "\n",
        "    # Build inverted index keyword → set(segment indices)\n",
        "    segment_tokens = [extract_keywords(seg.text) for seg in segments]\n",
        "    inverted_index = {}\n",
        "    for idx, toks in enumerate(segment_tokens):\n",
        "        for tok in toks:\n",
        "            inverted_index.setdefault(tok, set()).add(idx)\n",
        "\n",
        "    print(f\"🧮 Using similarity threshold = {similarity_threshold:.3f}\\n\")\n",
        "\n",
        "    while True:\n",
        "        q = input(\"❓ Ask a question (or 'exit'): \").strip()\n",
        "        if not q:\n",
        "            continue\n",
        "        if q.lower() == 'exit':\n",
        "            print(\"👋 Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # 1) Extract & show keywords\n",
        "        keywords = extract_keywords(q)\n",
        "        print(f\"🔑 Keywords: {keywords}\")\n",
        "\n",
        "        # 2) Candidate filter by keywords\n",
        "        cands = set()\n",
        "        for kw in keywords:\n",
        "            cands |= inverted_index.get(kw, set())\n",
        "        idx_list = list(cands) if cands else list(range(len(segments)))\n",
        "\n",
        "        # 3) Embed & score + keyword boost\n",
        "        q_emb      = model.encode([q], convert_to_tensor=False)\n",
        "        sims_sub   = cosine_similarity(q_emb, segment_embeddings[idx_list])[0]\n",
        "        boosts     = np.array([sum(1 for kw in keywords if kw in segment_tokens[i])\n",
        "                               for i in idx_list])\n",
        "        final_sims = sims_sub + boost_weight * boosts\n",
        "\n",
        "        # 4) Pick best\n",
        "        best_loc   = int(np.argmax(final_sims))\n",
        "        best_score = float(final_sims[best_loc])\n",
        "        best_idx   = idx_list[best_loc]\n",
        "\n",
        "        # 5) If below threshold, auto-fallback to top 3 chunks\n",
        "        if best_score < similarity_threshold:\n",
        "            print(\"\\n🤔 Not confident enough—here are the top 3 chunks instead:\")\n",
        "            top3 = np.argsort(final_sims)[-3:][::-1]\n",
        "            for i, loc in enumerate(top3, 1):\n",
        "                seg = segments[idx_list[loc]]\n",
        "                snippet = seg.text.replace(\"\\n\", \" \")[:FALLBACK_SNIPPET_LEN].rstrip()\n",
        "                print(f\"  {i}. [{seg.section_id}] {seg.title}\\n     {snippet}…\\n\")\n",
        "            choice = input(\"Pick 1–3 or Enter to retry: \").strip()\n",
        "            if choice in ('1','2','3'):\n",
        "                sel = top3[int(choice)-1]\n",
        "                best_idx   = idx_list[sel]\n",
        "                best_score = float(final_sims[sel])\n",
        "            else:\n",
        "                print()\n",
        "                continue\n",
        "\n",
        "        # 6) Display answer with highlights\n",
        "        seg = segments[best_idx]\n",
        "        print(f\"\\n🔹 Section {seg.section_id} — {seg.title} — Score {best_score:.3f}\\n\")\n",
        "        print(highlight_text(seg.text, keywords), \"\\n\" + \"—\"*40 + \"\\n\")\n",
        "\n",
        "# ─── Main script ────────────────────────────────────────────────────────────────\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Read full text\n",
        "    with open(\"Section11.2.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        full_text = f.read()\n",
        "\n",
        "    # 2) Split into chunks and extract metadata\n",
        "    pattern = r\"(11\\.2\\.\\d+(?:\\.\\d+)*\\.)\\s*([\\s\\S]*?)(?=(?:11\\.2\\.\\d|\\Z))\"\n",
        "    matches = re.findall(pattern, full_text)\n",
        "    Segment = namedtuple(\"Segment\", [\"section_id\", \"title\", \"text\"])\n",
        "    segments = []\n",
        "    for sec_id, body in matches:\n",
        "        lines = body.strip().split(\"\\n\", 1)\n",
        "        title = lines[0].strip()\n",
        "        text  = lines[1].strip() if len(lines) > 1 else \"\"\n",
        "        segments.append(Segment(sec_id, title, text))\n",
        "\n",
        "    # 3) Embed all segments\n",
        "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    texts = [seg.text for seg in segments]\n",
        "    segment_embeddings = model.encode(texts, convert_to_tensor=False)\n",
        "\n",
        "    # 4) Auto-calibrate threshold via nearest-neighbor median\n",
        "    threshold = calibrate_nn_median(segment_embeddings)\n",
        "\n",
        "    # 5) Launch interactive lookup\n",
        "    interactive_lookup(model, segments, segment_embeddings, threshold)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwwNCKPyEI-3",
        "outputId": "abe2f0cc-1e22-4051-afd4-9b86bc359182"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧮 Using similarity threshold = 0.732\n",
            "\n",
            "❓ Ask a question (or 'exit'): what does a float come in handy for?\n",
            "🔑 Keywords: ['does', 'float', 'come', 'handy']\n",
            "\n",
            "🤔 Not confident enough—here are the top 3 chunks instead:\n",
            "  1. [11.2.1.11.] Specific\n",
            "     Upgrade  Requirements  for  Float  Homes  and  Marinas  1) Except as permitted by Sentence (2), where a marina is altered, all new work shall comply with Subsection  12.2.2. and the marina shall be upgraded to an acceptable level as determined by the Upgrade Mechanism Model in  Notes to Part 11.  2)…\n",
            "\n",
            "  2. [11.2.1.3.] , they shall be installed throughout the storey on which the new\n",
            "     dwelling unit is to be located and all storeys below the new dwelling unit.  Rev.  14107  4) A building need not be sprinklered in accordance with Sentence (1), if the construction value of the alteration  does not exceed $250,000.   Table…\n",
            "\n",
            "  3. [11.2.1.] 5)\n",
            "     1) Where an alteration to a building is a self-contained volumetric space that is separated from the remainder  of the building by a non-combustible vertical fire separation with a 2 h fire resistance rating, the upgrade requirements of  this Part do not apply to the remainder of the building provid…\n",
            "\n",
            "Pick 1–3 or Enter to retry: 1\n",
            "\n",
            "🔹 Section 11.2.1.11. — Specific — Score 0.256\n",
            "\n",
            "Upgrade \n",
            "Requirements \n",
            "for \n",
            "**Float** \n",
            "Homes \n",
            "and \n",
            "Marinas \n",
            "1) Except as permitted by Sentence (2), where a marina is altered, all new work shall comply with Subsection \n",
            "12.2.2. and the marina shall be upgraded to an acceptable level as determined by the Upgrade Mechanism Model in \n",
            "Notes to Part 11. \n",
            "2) Except as required by Sentence (3); Sentences 12.2.2.7.(1), and 12.2.2.8.(1) need not apply to a marina. \n",
            "Rev. \n",
            "\n",
            "3) Where the total construction value of an alteration to a marina exceeds 50% of the replacement value of the 12511; \n",
            "13826\n",
            "\n",
            "marina as determined at the application stage for alteration, then the marina shall comply with Subsection 12.2.2. \n",
            "\n",
            "4) Where a **float** home is altered \n",
            "a) new work shall comply with Subsecetion 12.2.2. of Division B and this By-law, and \n",
            "b) the **float** home shall be upgraded to an acceptable level in accordance with Article \n",
            "————————————————————————————————————————\n",
            "\n",
            "❓ Ask a question (or 'exit'): exit\n",
            "👋 Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QwhfOPXtENHF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}