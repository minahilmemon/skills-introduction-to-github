{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWG2v1nzcQ6/CQpw5g285/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minahilmemon/skills-introduction-to-github/blob/main/MD-User_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08E2a6g9lrX2"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "import re\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# 1) Define your richer Segment with a page field\n",
        "Segment = namedtuple(\"Segment\", [\n",
        "    \"section_id\",   # e.g. \"11.2.1.3.\"\n",
        "    \"title\",        # e.g. \"Accessibility Upgrade Requirements\"\n",
        "    \"text\",         # the clause text\n",
        "    \"page\"          # page number in the PDF\n",
        "])\n",
        "\n",
        "# 2) Load & chunk the PDF, capturing page numbers\n",
        "def load_segments_with_page(pdf_path: str):\n",
        "    pattern = r\"(11\\.2\\.\\d+(?:\\.\\d+)*\\.)\\s*([\\s\\S]*?)(?=(?:11\\.2\\.\\d|\\Z))\"\n",
        "    segments = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page_num, page in enumerate(pdf.pages, start=1):\n",
        "            page_text = page.extract_text() or \"\"\n",
        "            for sec_id, body in re.findall(pattern, page_text):\n",
        "                lines = body.strip().split(\"\\n\", 1)\n",
        "                title = lines[0].strip()\n",
        "                text  = lines[1].strip() if len(lines) > 1 else \"\"\n",
        "                segments.append(Segment(sec_id, title, text, page_num))\n",
        "    return segments\n",
        "\n",
        "segments = load_segments_with_page(\"Section11.2.pdf\")\n",
        "\n",
        "# 3) Compute embeddings once\n",
        "model = SentenceTransformer(\"intfloat/e5-large-v2\")\n",
        "texts = [f\"{seg.section_id} {seg.title}\\n{seg.text}\" for seg in segments]\n",
        "embeddings = model.encode(texts, batch_size=16, show_progress_bar=True)\n",
        "\n",
        "# 4) Calibrate threshold via nearest‐neighbour median\n",
        "def calibrate_nn_median(embs: np.ndarray) -> float:\n",
        "    # pairwise cosine similarities\n",
        "    sims = cosine_similarity(embs)\n",
        "    # ignore self‐sims\n",
        "    np.fill_diagonal(sims, -np.inf)\n",
        "    # best other‐chunk similarity for each chunk\n",
        "    best_scores = sims.max(axis=1)\n",
        "    # threshold = median of those best‐scores\n",
        "    return float(np.median(best_scores))\n",
        "\n",
        "THRESHOLD = calibrate_nn_median(embeddings)\n",
        "print(f\"Calibrated similarity threshold: {THRESHOLD:.3f}\")\n",
        "\n",
        "# 5) Pair up segments with their embeddings\n",
        "embedded_segments = list(zip(segments, embeddings))\n",
        "\n",
        "# 6) Query function using NN threshold\n",
        "def find_best_match(query: str, fallback_top_k=3):\n",
        "    q_emb = model.encode([query])[0]\n",
        "    sims = np.array([cosine_similarity([q_emb], [emb])[0,0]\n",
        "                     for _, emb in embedded_segments])\n",
        "    best_idx = sims.argmax()\n",
        "    if sims[best_idx] >= THRESHOLD:\n",
        "        seg = embedded_segments[best_idx][0]\n",
        "        return {\n",
        "            \"answer\": seg.text,\n",
        "            \"section\": seg.section_id,\n",
        "            \"title\": seg.title,\n",
        "            \"page\": seg.page,\n",
        "            \"similarity\": float(sims[best_idx])\n",
        "        }\n",
        "    else:\n",
        "        top_k_idx = sims.argsort()[-fallback_top_k:][::-1]\n",
        "        return [{\n",
        "            \"section\": embedded_segments[i][0].section_id,\n",
        "            \"title\": embedded_segments[i][0].title,\n",
        "            \"page\": embedded_segments[i][0].page,\n",
        "            \"similarity\": float(sims[i])\n",
        "        } for i in top_k_idx]\n",
        "\n",
        "# 7) Run interactively\n",
        "if __name__ == \"__main__\":\n",
        "    user_q = input(\"Enter your question: \")\n",
        "    result = find_best_match(user_q)\n",
        "    if isinstance(result, dict):\n",
        "        print(f\"\\n✔ Found answer in {result['section']} (page {result['page']})\")\n",
        "        print(result[\"answer\"])\n",
        "        print(f\"(sim={result['similarity']:.3f})\")\n",
        "    else:\n",
        "        print(\"\\n⚠ No confident match; here are the top suggestions:\")\n",
        "        for r in result:\n",
        "            print(f\" • {r['section']} (page {r['page']}), sim={r['similarity']:.3f}\")\n",
        "            print(f\"   » {r['title']}\")\n"
      ]
    }
  ]
}